<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link rel="icon" type="image/png" href="/images/favicon.png">

<title>คำนวณเวลาอ่านบทความใน Jekyll โดยการตัดคำแบบไทย | KT</title>

<meta name="description" content="Write an awesome description for your new site here. It will appear in your document head meta (for Google search results) and in your feed.xml site description." />

<link rel="stylesheet" href="/_bridgetown/static/index.NXSPJ6K7.css" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/glightbox/dist/css/glightbox.min.css" />
<script type="module">
  import 'https://cdn.jsdelivr.net/gh/mcstudios/glightbox/dist/js/glightbox.min.js';
</script>
<script defer data-domain="karn18.github.io" src="https://analytics.karn.work/js/plausible.js"></script>
<script src="/_bridgetown/static/index.TU2OTUPV.js" defer></script>


  </head>
  <body class="post ">
    <nav>
  <ul>
    <li><a href="/">Home</a></li>
    
    
  </ul>
</nav>

    <main>
      <main data-controller="lightbox">
  <h1>คำนวณเวลาอ่านบทความใน Jekyll โดยการตัดคำแบบไทย</h1>

  <p>บทความนี้จะกล่าวถึงการคำนวณเวลาที่ใช้ในการอ่านบทความ ซึ่งในส่วนของ <strong>Jekyll</strong> จะมีปลักอินที่ชื่อ <strong>liquid_reading_time</strong> ที่ถูกนำมาใช้ในการคำนวณเวลาโดยเฉลี่ยในการอ่านบทความหนึ่งๆ และแสดงให้ผู้อ่านเห็น <!--more-->โดยมีสูตรที่ว่า</p>

<blockquote>
  <p>จำนวนคำทั้งหมดในบทความ / ความเร็วเฉลี่ยในการอ่าน = ระยะเวลาในการอ่าน</p>
</blockquote>

<p>ถ้าดูแล้วการใช้ปลักอินดังกล่าวก็ดูน่าจะตอบโจทย์แล้วใช่หรือไม่ <strong>แต่</strong>อย่าลืมว่าการนับจำนวนคำระหว่างภาษาไทยกับภาษาอังกฤษนั้นแตกต่างกัน กล่าวคือโดยปกติคำหนึ่งๆ ในภาษาอังกฤษจะถูกแยกจากกันด้วยช่องว่าง (whitespace) ส่วนภาษาไทยนั้นการแยกคำออกมานั้นมีความซับซ้อนกว่ามาก ดังนั้นการใช้ปลักอินที่ตัดคำโดยใช้ช่องว่างจึงไม่ตอบโจทย์</p>

<p>เอ๊ะแล้วอย่างงี้จะใช้ปลักอินตัวไหนมาช่วยในการตัดคำไทยดี ซึ่งต้องบอกเลยว่าถ้าหากใช้ <strong>Ruby</strong> อย่างเดียวนั้นคงเป็นไปได้ยาก เนื่องจากไลบราลีที่ใช้สำหรับตัดคำไทย<strong>ไม่มีผู้พัฒนา</strong>ในภาษา <strong>Ruby</strong> ทำให้ต้องไปเพิ่งไลบราลี <a href="https://github.com/PyThaiNLP/pythainlp">pythainlp</a> ในภาษา <strong>Python</strong> แทน ซึ่งไลบราลีตัวนี้มีนักพัฒนาคนไทยช่วยกัน และเผยแพร่ให้นักพัฒนาคนอื่นๆ ได้ใช้งานกัน</p>

<p>ฉะนั้นในบทความนี้จะเป็นการรวมร่างกันทำงานระหว่างไลบราลี <strong>liquid_reading_time</strong> (Ruby) กับ <strong>pythainlp</strong> (Python) โดย</p>
<ul>
  <li><strong>pythailnp</strong> นำมาใช้ในการตัดคำภาษาไทยที่มาจากบทความ</li>
  <li><strong>liquid_reading_time</strong> นำมาใช้ในการคำนวณระยะเวลาในการอ่าน</li>
</ul>

<h2 id="ลงมือปรับแต่งกันเลย">ลงมือปรับแต่งกันเลย</h2>
<ul>
  <li>เริ่มต้นโดยการ fork ปลักอินมาก่อน โดยเข้าไปที่ <a href="https://github.com/bdesham/reading_time">liquid_reading_time</a> แล้วก็ clone project มาไว้ยังเครื่องคอมพิวเตอร์ของเรา</li>
  <li>เข้าไปยังไฟล์ที่ชื่อ <strong>lib/liquid_reading_time.rb</strong> จากนั้นทำการเพิ่มโค้ดสำหรับเรียกใช้งานโปรแกรม <strong>word_tokenizer.py</strong> ผ่านฟังก์ชันที่ชื่อ <strong>tokenize_words</strong> และเปลี่ยนการเรียกใช้ฟังก์ชัน <strong>count_words</strong> ดังแสดงในโค้ดด้านล่าง</li>
</ul>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">def</span> <span class="nf">count_words</span><span class="p">(</span><span class="n">html</span><span class="p">)</span>
      <span class="n">tokenize_words</span><span class="p">(</span><span class="n">words</span><span class="p">(</span><span class="n">html</span><span class="p">).</span><span class="nf">join</span><span class="p">(</span><span class="s1">' '</span><span class="p">))</span> <span class="c1"># Add this line</span>
      <span class="c1"># words(html).length # Comment this line</span>
    <span class="k">end</span>
  <span class="k">end</span>

  <span class="o">...</span>
  <span class="c1"># Add new method</span>
  <span class="k">def</span> <span class="nf">tokenize_words</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="n">cmd</span> <span class="o">=</span> <span class="sb">`python word_tokenizer.py "</span><span class="si">#{</span><span class="n">text</span><span class="si">}</span><span class="sb">"`</span>
    <span class="n">cmd</span><span class="p">.</span><span class="nf">to_i</span>
  <span class="k">end</span>
</code></pre></div></div>

<ul>
  <li>เข้าไปยังโฟลเดอร์เว็บไซด์ของเรา และทำการสร้างไฟล์ <strong>word_tokenizer.py</strong> ซึ่งเป็นโปรแกรมทีรับฟารามิเตอร์เป็นเนื้อหาของบทความ แล้วจะส่งคืนค่าจำนวนคำที่ตัดได้คืนกลับไป โดยผ่านการแสดงผลทาง stdout</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="kn">import</span> <span class="nn">sys</span>
  <span class="kn">from</span> <span class="nn">pythainlp</span> <span class="kn">import</span> <span class="n">sent_tokenize</span><span class="p">,</span> <span class="n">word_tokenize</span>

  <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">sys</span><span class="p">.</span><span class="n">argv</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
      <span class="n">content</span> <span class="o">=</span> <span class="n">sys</span><span class="p">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
      <span class="n">sys</span><span class="p">.</span><span class="n">stdout</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">content</span><span class="p">,</span> <span class="n">keep_whitespace</span><span class="o">=</span><span class="bp">False</span><span class="p">))))</span>
  <span class="k">else</span><span class="p">:</span>
      <span class="n">sys</span><span class="p">.</span><span class="n">stdout</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="s">'0'</span><span class="p">)</span>
  <span class="n">sys</span><span class="p">.</span><span class="nb">exit</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></div>
<ul>
  <li>ทำการแก้ไข Gemfile ของ <strong>liquid_reading_time</strong> ให้โหลดจาก repo ของเราที่ได้ fork ออกมาแทน repo หลัก</li>
  <li>ทดสอบการประเมินเวลาของบทความกัน ซึ่งปรากฏว่าหลังจากเปลี่ยนมาใช้การตัดคำแบบไทยในการประเมินเวลาการอ่านบทความ จะได้ระยะเวลาในการประเมินที่ค่อนข้างใกล้เคียงกับเวลาที่ใช้อ่านจริง</li>
</ul>

<p><img src="/images/posts/2019/customize-reading-time-with-thai-nlp/reading_time_default.png" alt="Reading Time" width="400px" />
<em>ใช้ liquid_reading_time แบบปกติ</em></p>

<p><img src="/images/posts/2019/customize-reading-time-with-thai-nlp/reading_time_with_thai_nlp.png" alt="Custome Reading Time" width="400px" />
<em>ใช้ pythainlp ร่วมกับ liquid_reading_time</em></p>

<p><em>!!!</em> ทั้งนี้การตัดคำแบบไทยนั้นเหมาะที่จะนำมาใช้กับบทความที่มีเนื้อหาเป็นทั้งภาษาไทย และภาษาอังกฤษ แต่ถ้าในกรณีที่ผู้เขียนบล็อกที่เน้นใช้เนื้อหาเป็นภาษาอังกฤษแต่เพียงอย่างเดียว ก็ไม่จำเป็นต้องปรับแต่งปลั๊กอินเพิ่มใดๆ</p>

<p><em>!!!</em> ป.ล. การเรียกใช้งานโปรแกรมสำหรับตัดคำไทยจะทำให้ใช้ระยะเวลาในการแปลงไฟล์ Markdown ไปเป็น HTML นานขึ้นด้วย</p>

<h2 id="references">References:</h2>
<ul>
  <li><a href="https://github.com/PyThaiNLP/pythainlp">pythainlp</a></li>
  <li><a href="https://github.com/bdesham/reading_time">liquid_reading_time</a></li>
</ul>

</main>

    </main>
  </body>
</html>
